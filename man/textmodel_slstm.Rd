% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_slstm.R
\name{textmodel_slstm}
\alias{textmodel_slstm}
\title{stacked LSTM neural network model for text}
\usage{
textmodel_slstm(x, y, units = 512, dropout = 0.2, optimizer = "adam",
  loss = "categorical_crossentropy", metrics = "categorical_accuracy",
  ...)
}
\arguments{
\item{x}{the \link{dfm} on which the model will be fit.  Does not need to
contain only the training documents.}

\item{y}{vector of training labels associated with each document identified 
in \code{train}.  (These will be converted to factors if not already 
factors.)}

\item{units}{The number of network nodes used in the first layer of the
sequential model}

\item{dropout}{A floating variable bound between 0 and 1. It determines the
rate at which units are dropped for the linear transformation of the
inputs.}

\item{optimizer}{optimizer used to fit model to training data, see
\code{\link[keras]{compile.keras.engine.training.Model}}}

\item{loss}{objective loss function, see
\code{\link[keras]{compile.keras.engine.training.Model}}}

\item{metrics}{metric used to train algorithm, see
\code{\link[keras]{compile.keras.engine.training.Model}}}

\item{...}{additional options passed to
\code{\link[keras]{fit.keras.engine.training.Model}}}
}
\description{
This function is a wrapper for a stacked Long Short-Term Memory (LSTM) neural
network with two layers, implemented in the \pkg{keras} package.
}
\examples{
# need examples here
}
\keyword{textmodel}
