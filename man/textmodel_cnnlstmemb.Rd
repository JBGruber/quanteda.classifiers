% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_cnnlstmemb.R
\name{textmodel_cnnlstmemb}
\alias{textmodel_cnnlstmemb}
\title{sequential neural network model for text classification}
\usage{
textmodel_cnnlstmemb(x, y, units = 512, dropout1 = 0.2,
  dropout2 = 0.2, dropout3 = 0.2, wordembeddim = 30, filter = 48,
  kernel_size = 5, pool_size = 4, units_lstm = 128, words = NULL,
  maxsenlen = 50, optimizer = "adam",
  loss = "categorical_crossentropy", metrics = "categorical_accuracy",
  ...)
}
\arguments{
\item{x}{tokens object}

\item{y}{vector of training labels associated with each document identified 
in \code{train}.  (These will be converted to factors if not already 
factors.)}

\item{units}{The number of network nodes used in the first layer of the
sequential model}

\item{dropout1}{A floating variable bound between 0 and 1. It determines the
rate at which units are dropped for the linear transformation of the
inputs.}

\item{dropout2}{A floating variable bound between 0 and 1. It determines the
rate at which units are dropped for the linear transformation of the
inputs.}

\item{dropout3}{A floating variable bound between 0 and 1. It determines the
rate at which units are dropped for the linear transformation of the
inputs.}

\item{wordembeddim}{The number of word embedding dimensions to be fit}

\item{filter}{}

\item{kernel_size}{}

\item{pool_size}{Size of the max pooling windows.
\code{\link[keras]{layer_max_pooling_1d}}}

\item{units_lstm}{The number of nodes of the lstm layer}

\item{words}{The maximum number of words used to train model. Defaults to the number of features in \code{x}}

\item{maxsenlen}{The maximum sentence length of training data}

\item{optimizer}{optimizer used to fit model to training data, see
\code{\link[keras]{compile.keras.engine.training.Model}}}

\item{loss}{objective loss function, see
\code{\link[keras]{compile.keras.engine.training.Model}}}

\item{metrics}{metric used to train algorithm, see
\code{\link[keras]{compile.keras.engine.training.Model}}}

\item{...}{additional options passed to
\code{\link[keras]{fit.keras.engine.training.Model}}}
}
\description{
Explain
}
\examples{
\dontrun{
# create a dataset with evenly balanced coded and uncoded immigration sentences
corpcoded <- corpus_subset(data_corpus_manifestosentsUK, !is.na(crowd_immigration_label))
corpuncoded <- data_corpus_manifestosentsUK \%>\%
    corpus_subset(is.na(crowd_immigration_label) & year > 1980) \%>\%
    corpus_sample(size = ndoc(corpcoded))
corp <- corpcoded + corpuncoded

# form a tokens object
corptok <- tokens(texts(corp))

set.seed(1000)
tmod <- textmodel_cnnlstmemb(corptok, y = docvars(dfmat, "crowd_immigration_label"),
                        epochs = 5, verbose = 1)
pred <- predict(tmod, newdata = dfm_subset(dfmat, is.na(crowd_immigration_label)))
table(pred)
tail(texts(corpuncoded)[pred == "Immigration"], 10)
}
}
\keyword{textmodel}
